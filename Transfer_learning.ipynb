{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "TL of Alexnet with XGBoost as classifier applied to galaxy pictures dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "# Load model\n",
    "model = models.alexnet(pretrained=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit model class (to overload nn.Module class)\n",
    "class RefitModel(nn.Module):\n",
    "    def __init__(self, orgininal_model, num_classes):\n",
    "        super(RefitModel, self).__init__()\n",
    "        \n",
    "        self.features = orgininal_model.features # to keep convolitionnal layers as is\n",
    "        \n",
    "        # modify only classification layers\n",
    "        self.classifier = orgininal_model.classifier \n",
    "        self.classifier == nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256*6*6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        self.modelName = 'alexnet'\n",
    "        \n",
    "        for w in self.features.parameters():\n",
    "            w.required_grad = False # to freeze features weights\n",
    "    \n",
    "    # transfer features in classification layer\n",
    "    def forward(self,x):\n",
    "        f = self.features(x)\n",
    "        f = f.view(f.size(0), 256*6*6)\n",
    "        y = self.classifier(f)\n",
    "        return y\n",
    "    \n",
    "def preprocess(img):  \n",
    "    img = img.resize((224,224)).convert('RGB')\n",
    "    tensor = transforms.ToTensor()(img)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edge', 'other', 'smooth', 'spiral']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit model\n",
    "num_classes = 7\n",
    "refit_model = RefitModel(model, num_classes)\n",
    "\n",
    "# define training and test data directories\n",
    "data_dir = 'data/'\n",
    "train_dir = os.path.join(data_dir, 'train/')\n",
    "test_dir = os.path.join(data_dir, 'test/')\n",
    "\n",
    "# classes are folders in each directory with these names\n",
    "classes = os.listdir('data/train')\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images:  352\n",
      "Num test images:  48\n"
     ]
    }
   ],
   "source": [
    "# Load training data and fit to alexnet data\n",
    "train = datasets.ImageFolder(train_dir, transform=preprocess)\n",
    "test = datasets.ImageFolder(test_dir, transform=preprocess)\n",
    "\n",
    "# print out some data stats\n",
    "print('Num training images: ', len(train))\n",
    "print('Num test images: ', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "num_workers = 0\n",
    "train_loader = torch.utils.data.DataLoader(train,batch_size=batch_size,shuffle=True,num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test,batch_size=batch_size,shuffle=True,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "error = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(refit_model.parameters(), lr=learning_rate)\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = refit_model(inputs)\n",
    "        \n",
    "        # Calculate cross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print stats\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i%20 == 20:\n",
    "            print('epoch: %d, batch: %5d, loss: %.3f'%(epoch+1, i, running_loss/20))\n",
    "            running_loss = 0.0\n",
    "\n",
    "# Save model\n",
    "torch.save(refit_model, 'tl_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('tl_model.pth')\n",
    "model.eval()\n",
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "k = 5\n",
    "\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    inputs, label = data\n",
    "    out = model(inputs)\n",
    "    _, topk_catid = torch.topk(out, 1)\n",
    "    \n",
    "    y_test.append(int(labels[0]))\n",
    "    y_pred.append(int(topk_catid[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    cmap='YlGnBu', \n",
    "    linewidths=.2,\n",
    "    linecolor='gray',\n",
    "    cbar_kws={\"shrink\": .8},\n",
    "    annot = True,\n",
    "    fmt='d'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
